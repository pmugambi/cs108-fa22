{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae407f78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 6: Testing Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741bb38",
   "metadata": {},
   "source": [
    "**Reading**: Textbook chapter [11](https://umass-data-science.github.io/190fwebsite/textbook/11/testing-hypotheses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1220639a",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 6 is due **Monday, 11/1 at 8:00am**. Start early so that you can come to office hours if you're stuck. Check Moodle for the office hours schedule.\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f63318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d97ba",
   "metadata": {},
   "source": [
    "## 1. Catching Cheaters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80514c60",
   "metadata": {},
   "source": [
    "Suppose you are a casino owner, and your casino runs a very simple game of chance.  The dealer flips a coin.  The customer wins 9 dollars from the casino if it comes up heads and loses 10 dollars if it comes up tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb40c4a",
   "metadata": {},
   "source": [
    "**Question 1.** Assuming no one is cheating and the coin is fair, if a customer plays twice, what is the chance they make money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf8ff86",
   "metadata": {
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_winning_after_two_flips = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f811caf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77dc86b",
   "metadata": {},
   "source": [
    "**Question 2.** A certain customer plays the game 20 times and wins 13 of the bets.  You suspect that the customer is cheating!  That is, you think that their chance of winning is higher than the normal chance of winning. You decide to test your hunch using the outcomes of the 20 games you observed.\n",
    "\n",
    "Define the null hypothesis and alternative hypothesis for this investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bc7f3",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Null hypothesis:**\n",
    "\n",
    "**Alternative hypothesis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989b54a",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 3.** Given the outcome of 20 games, which of the following test statistics would be a reasonable choice for this hypothesis test? \n",
    "\n",
    "*Hint*: For a refresher on choosing test statistics, check out [Section 11.3 of the textbook](https://umass-data-science.github.io/190fwebsite/textbook/11/3/decisions-and-uncertainty/).\n",
    "\n",
    "1. Whether there is at least one win.\n",
    "1. Whether there is at least one loss.\n",
    "1. The number of wins.\n",
    "1. The number of wins minus the number of losses.\n",
    "1. The total variation distance between the probability distribution of a fair coin and the observed distribution of heads and tails.\n",
    "1. The total amount of money that the customer won.\n",
    "\n",
    "Assign `reasonable_test_statistics` to an array of numbers corresponding to these test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b14f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reasonable_test_statistics = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f5b7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec831f",
   "metadata": {},
   "source": [
    "**Question 4.** Suppose you decide to use the number of wins as your test statistic. Write a function called `simulate` that simulates your test statistic.  It should take no arguments.  It should return the number of wins in 20 games simulated under the assumption that the result of each game is sampled from a fair coin (one that is equally likely to get heads or tails).\n",
    "\n",
    "*Hint*: You may find the `sample_proportions` function [from the textbook](https://umass-data-science.github.io/190fwebsite/textbook/11/1/assessing-models/) to be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aec1fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    # Simulates the number times you win a game with 50/50 chance of win/lose\n",
    "    ...\n",
    "    return games_won\n",
    "\n",
    "simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e3209",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e75302",
   "metadata": {},
   "source": [
    "**Question 5.** Using 10,000 trials, generate simulated values of the number of wins in 20 games. Assign `test_statistics_under_null` to an array that stores the result of each of these trials.\n",
    "\n",
    "*Hint*: Feel free to use the function you defined in Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66757057",
   "metadata": {
    "for_assignment_type": "student",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_statistics_under_null = make_array()\n",
    "repetitions = 10000\n",
    "\n",
    "...\n",
    "\n",
    "test_statistics_under_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f821d53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c9004",
   "metadata": {},
   "source": [
    "**Question 6.** Using the results from Question 5, generate a histogram of the empirical distribution of the number of wins in 20 games."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6238c0",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95aaff88",
   "metadata": {
    "for_assignment_type": "student",
    "manual_grade": true,
    "manual_problem_id": "catching_cheaters_6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03df7b5",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 7.** Compute an empirical P-value for this test. Remember from the question that: the customer plays the game 20 times and wins 13 of the bets\n",
    "\n",
    "*Hint:* Which values of our test statistic are in the direction of the alternative hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4bd73f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198db41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20362dcf",
   "metadata": {},
   "source": [
    "## 2. Landing a Spacecraft\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3478f1",
   "metadata": {},
   "source": [
    "(Note: This problem describes something that's close to [a real story with a very exciting video](http://www.space.com/29119-spacex-reusable-rocket-landing-crash-video.html), but the details have been changed somewhat.)\n",
    "\n",
    "SpaceY, a company that builds and tests spacecraft, is testing a new reusable launch system.  Most spacecraft use a \"first stage\" rocket that propels a smaller payload craft away from Earth, then falls back to the ground and crashes.  SpaceY's new system is designed to land safely at a landing pad at a certain location, ready for later reuse.  If it doesn't land in the right location, it crashes, and the (very expensive) vehicle is destroyed.\n",
    "\n",
    "SpaceY has tested this system over 1000 times.  Ordinarily, the vehicle doesn't land exactly on the landing pad.  For example, a gust of wind might move it by a few meters just before it lands.  It's reasonable to think of these small errors as random.  That is, the landing locations are drawn from some distribution over locations on the surface of Earth, centered around the landing pad.\n",
    "\n",
    "Run the next cell to see a plot of those locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da14e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_landing_spots = Table.read_table(\"ordinary_landing_spots.csv\")\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Landing locations\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8eeac",
   "metadata": {},
   "source": [
    "During one test, the vehicle lands far away from the landing pad and crashes.  SpaceY investigators suspect there was a problem unique to this landing, a problem that wasn't part of the ordinary pattern of variation in landing locations.  They think a software error in the guidance system caused the craft to incorrectly attempt to land at a spot other than the landing pad.  The guidance system engineers think there was nothing out of the ordinary in this landing, and that there was no special problem with the guidance system.\n",
    "\n",
    "Run the cell below to see a plot of the 1100 ordinary landings and the crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4fbbbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_spot = make_array(80.59, 30.91)\n",
    "ordinary_landing_spots.scatter(\"x\", label=\"Other landings\")\n",
    "plt.scatter(0, 0, c=\"w\", s=1000, marker=\"*\", label=\"Landing pad\")\n",
    "plt.scatter(landing_spot.item(0), landing_spot.item(1), marker=\"*\", c=\"r\", s=1000, label=\"Crash site\")\n",
    "plt.legend(scatterpoints=1, bbox_to_anchor=(1.6, .5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c8ea2",
   "metadata": {},
   "source": [
    "**Question 1.** Suppose we'd like to use hypothesis testing to shed light on this question.  We've written down an alternative hypothesis below.  What is a reasonable null hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c66b52",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Null hypothesis:**\n",
    "\n",
    "**Alternative hypothesis:** This landing was special; its location was a draw from some other distribution, not the distribution from which the other 1100 landing locations were drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291074b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.** What's a good test statistic for this hypothesis test? \n",
    "\n",
    "*Hint:* A test statistic can be almost anything, but a *good* test statistic varies informatively depending on whether the null is true. So for this example, we might think about a test statistic that would be small if the null is true, and large otherwise. If we want to compare landings, we might want to see *how far* each landing is from some *reference point*, so we can compare all landings from the same vantage point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1617c",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Test statistic:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e7773",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 3.** Write a function called `landing_test_statistic`.  It should take two arguments: an \"x\" location and a \"y\" location (both numbers).  It should return the value of your test statistic for a landing at those coordinates. Assume that the landing pad is (0,0). There are no tests for this question because it will be graded manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581e05d",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cf4793b",
   "metadata": {
    "manual_grade": true,
    "manual_problem_id": "landing_3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def landing_test_statistic(x_coordinate, y_coordinate):\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc0a3f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 4.** The next three cells when run compute a P-value using your test statistic. **Describe the test procedure in words.** Is there a simulation involved? If so, what is being simulated? If not, why not? Where are we getting the data from? What kind of calculations are being performed? How are we calculating our p-value? \n",
    "\n",
    "*Hint:* Think about what a [simulation](https://umass-data-science.github.io/190fwebsite/textbook/09/3/simulation/) actually consists of."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d1aa3",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8956d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_test_stat = landing_test_statistic(\n",
    "    landing_spot.item(0),\n",
    "    landing_spot.item(1))\n",
    "\n",
    "observed_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ec878",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stats = make_array()\n",
    "repetitions = ordinary_landing_spots.num_rows\n",
    "\n",
    "for i in np.arange(repetitions):\n",
    "    null_stat = landing_test_statistic(\n",
    "        ordinary_landing_spots.column('x').item(i),\n",
    "        ordinary_landing_spots.column('y').item(i))\n",
    "    null_stats = np.append(null_stats, null_stat)\n",
    "    \n",
    "null_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = np.count_nonzero(null_stats >= observed_test_stat) / len(null_stats)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f3c9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409127eb",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3. Testing Dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de7c95",
   "metadata": {},
   "source": [
    "Students in a Data Science class want to figure out whether a six-sided die is fair or not. On a fair die, each face of the die appears with chance 1/6 on each roll, regardless of the results of other rolls.  Otherwise, a die is called unfair.  We can describe a die by the probability of landing on each face.  This table describes an example of a die that is unfairly weighted toward 1:\n",
    "\n",
    "|Face|Probability|\n",
    "|--|--|\n",
    "|1|.5|\n",
    "|2|.1|\n",
    "|3|.1|\n",
    "|4|.1|\n",
    "|5|.1|\n",
    "|6|.1|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b240552",
   "metadata": {},
   "source": [
    "**Question 1.** Define a null hypothesis and an alternative hypothesis to test whether a six-sided die is fair or not. \n",
    "\n",
    "*Hint:* Remember that an unfair die is one for which each face does not have an equal chance of appearing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407bc56",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Null hypothesis:**\n",
    "\n",
    "**Alternative hypothesis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e7911",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "We decide to test the die by rolling it 5 times. The proportions of the 6 faces in these 5 rolls are stored in a table with 6 rows.  For example, here is the table we'd make if the die rolls ended up being 1, 2, 3, 3, and 5:\n",
    "\n",
    "|Face|Proportion|\n",
    "|--|--|\n",
    "|1|.2|\n",
    "|2|.2|\n",
    "|3|.4|\n",
    "|4|.0|\n",
    "|5|.2|\n",
    "|6|.0|\n",
    "\n",
    "The function `mystery_test_statistic`, defined below, takes a single table like this as its argument and returns a number (which we will use as a test statistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a022210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We've intentionally used obscurantist function and\n",
    "# variable names to avoid giving away answers.  It's rarely\n",
    "# a good idea to use names like \"x\" in your code.\n",
    "\n",
    "def mystery_test_statistic(sample):\n",
    "    x = sum(sample.column(\"Face\")*sample.column(\"Proportion\"))\n",
    "    y = np.mean(np.arange(1, 6+1, 1))\n",
    "    return abs(x - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a766347",
   "metadata": {},
   "source": [
    "**Question 2.** Describe in English what the test statistic is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efe2ea",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a476aec",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "The function `simulate_observations_and_test` takes as its argument a table describing the probability distribution of a die.  It simulates one set of 5 rolls of that die, then tests the null hypothesis about that die using our test statistic function above.  It returns `False` if it *rejects* the null hypothesis about the die, and `True` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f04df3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The probability distribution table for a fair die:\n",
    "fair_die = Table().with_columns(\n",
    "        \"Face\", np.arange(1, 6+1),\n",
    "        \"Probability\", [1/6, 1/6, 1/6, 1/6, 1/6, 1/6])\n",
    "\n",
    "def simulate_observations_and_test(actual_die):\n",
    "    \"\"\"Simulates die rolls from actual_die and tests the hypothesis that the die is fair.\n",
    "    \n",
    "    Returns False if that hypothesis is rejected, and True otherwise.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sample_size = 5\n",
    "    p_value_cutoff = .2\n",
    "    num_simulations = 250\n",
    "    \n",
    "    # Compute the observed value of the test statistic.\n",
    "    observation_set = sample_proportions(sample_size, actual_die.column(\"Probability\"))\n",
    "    observation_props_table = Table().with_columns('Face', actual_die.column('Face'), 'Proportion', observation_set)\n",
    "    observed_statistic = mystery_test_statistic(observation_props_table)\n",
    "    \n",
    "    # Simulate the test statistic repeatedly to get an \n",
    "    # approximation to the probability distribution of \n",
    "    # the test statistic, as predicted by the model in \n",
    "    # the null hypothesis. Store the simulated values \n",
    "    # of the test statistic in an array.\n",
    "    simulated_statistics = make_array()\n",
    "    for _ in np.arange(num_simulations):\n",
    "        one_observation_set_under_null = sample_proportions(sample_size, fair_die.column(\"Probability\"))\n",
    "        simulated_props_table = Table().with_columns('Face', fair_die.column('Face'), 'Proportion', one_observation_set_under_null)\n",
    "        simulated_statistic = mystery_test_statistic(simulated_props_table)\n",
    "        simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "        \n",
    "    # Compute the P-value\n",
    "    p_value = np.count_nonzero(simulated_statistics >= observed_statistic) / num_simulations\n",
    "    \n",
    "    # If the P-value is below the cutoff, reject the \n",
    "    # null hypothesis and return False. Otherwise, \n",
    "    # return True.\n",
    "    return p_value >= p_value_cutoff\n",
    "\n",
    "# Calling the function to simulate a test of a fair die:\n",
    "simulate_observations_and_test(fair_die)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659c6eb",
   "metadata": {},
   "source": [
    "**Question 3.** Use your knowledge of hypothesis tests and interpretation of the code above to compute the probability that `simulate_observations_and_test` returns `False` when its argument is `fair_die` (which is defined above the function).  You can call the function a few times to see what it does, but **don't** perform a simulation to compute this probability.  Use your knowledge of hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f221ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probability_of_false = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28011d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39a027",
   "metadata": {},
   "source": [
    "**Question 4.** Why is your answer to Question 3 the correct probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0afef2",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843c1ca",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 5.** Simulate the process of running `simulation_observations_and_test` 300 times. Assign `test_results` to an array that stores the result of each of these trials.\n",
    "\n",
    "**Note:** This will be a little slow. 300 repetitions of the simulation may require up to a minute or so of computation, and should suffice to get an answer that's roughly correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a86e146",
   "metadata": {
    "for_assignment_type": "student",
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_test_simulations = 300\n",
    "test_results = make_array()\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change the following line.\n",
    "test_results.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1b4f0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d1df8",
   "metadata": {},
   "source": [
    "**Question 6.** Verify your answer to Question 3 by computing an approximate probability that `simulation_observations_and_test` returns `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d829bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approximate_probability_of_false = ...\n",
    "approximate_probability_of_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e5841",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7ee556",
   "metadata": {},
   "source": [
    "**Question 7.** From the perspective of someone who wants to know the truth about the die, is it good or bad for the function to return `False` when its argument is `fair_die`? Why is it good or bad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34e66a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583cf9d",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b889df2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c4f48",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "otter": {
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 0 <= p_winning_after_two_flips <= 1\n",
         "failure_message": "Probability must be between 0-1",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.3": {
     "name": "q1.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(reasonable_test_statistics) == np.ndarray\n",
         "failure_message": "Did you use make_array?",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4": {
     "name": "q1.4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 0 <= float(simulate()) <= 20\n",
         "failure_message": "This function should output between 0-20 wins",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.std([simulate() for _ in range(1000)]) > 0\n",
         "failure_message": "It looks like your simulation isn't random",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.5": {
     "name": "q1.5",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(test_statistics_under_null) == 10000\n",
         "failure_message": "This array should contain 10000 trials",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.7": {
     "name": "q1.7",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 0 <= p_value <= 1\n",
         "failure_message": "p_value should be between 0 and 1",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.3": {
     "name": "q3.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 0 <= probability_of_false <= 1\n",
         "failure_message": "This should be a probability",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.5": {
     "name": "q3.5",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(test_results) == 300\n",
         "failure_message": "test_results should contain 300 simulations",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.6": {
     "name": "q3.6",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 0 <= approximate_probability_of_false <= 1\n",
         "failure_message": "This should be a probability",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

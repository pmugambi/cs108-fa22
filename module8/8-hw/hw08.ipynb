{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8: Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: Textbook chapter [14](https://umass-data-science.github.io/190fwebsite/textbook/14/why-the-mean-matters/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "Homework 8 is due **Thursday, 11/17 at 11:00pm**. Start early so that you can come to office hours if you're stuck.\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "For all problems that you must write our explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook! For example, if you use `max_temperature` in your answer to one question, do not reassign it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Bootstrap and The Normal Curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will explore a dataset that includes the safety inspection scores for restauraunts in the city of Austin, Texas.  We will be interested in determining the average restaurant score (out of 100) for the city from a random sample of the scores.  We'll compare two methods for computing a confidence interval for that quantity: the bootstrap resampling method, and an approximation based on the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "pop_restaurants = Table.read_table('restaurant_inspection_scores.csv').drop(5,6)\n",
    "pop_restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** (Ungraded):\n",
    "Plot a histogram of the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "This is the population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = np.mean(pop_restaurants.column(3))\n",
    "pop_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is impossible to find complete datasets like this.  Imagine we instead had access only to a random sample of 100 restaurant inspections, called `restaurant_sample`.  That table is created below. We are interested in using this sample to estimate the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "restaurant_sample = pop_restaurants.sample(100, with_replacement=False)\n",
    "restaurant_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2** (Ungraded): Plot a histogram of the **sample** scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "This is the **sample mean**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Complete the function `bootstrap_scores` below. It should take no arguments. It should simulate drawing 5000 resamples from `restaurant_sample` and computing the mean restaurant score in each resample.  It should return an array of those 5000 resample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Resample from resampled mean 5000 times\n",
    "np.random.seed(123)\n",
    "\n",
    "def bootstrap_scores(restaurant_sample):\n",
    "    resampled_means = ...\n",
    "    for i in range(5000):\n",
    "        resampled_mean = ...\n",
    "        resampled_means = ...\n",
    "    return resampled_means\n",
    "\n",
    "resampled_means = bootstrap_scores(restaurant_sample)\n",
    "resampled_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the histogram of the **resampled means**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Resampled Means', resampled_means).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Compute a 95 percent confidence interval for the average restaurant score using the array `resampled_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "manual_problem_id": "bootstrap_4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "print(\"95% confidence interval for the average restaurant score, computed by bootstrapping:\\n(\",lower_bound, \",\", upper_bound, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: Does the distribution of the resampled mean scores look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you should expect this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 6:** Does the distribution of the **sample scores** (notice we're no longer talking about the resampled means) look normally distributed? State \"yes\" or \"no\" and describe in one sentence why you should expect this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "For the last question, you'll need to recall two facts.\n",
    "1. If a group of numbers has a normal distribution, around 95% of them lie within 2 standard deviations of their mean.\n",
    "2. The Central Limit Theorem tells us the quantitative relationship between\n",
    "    * the standard deviation of an array of numbers and\n",
    "    * the standard deviation of an array of means of samples taken from those numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** Without referencing the array `resampled_means` or performing any new simulations, calculate an interval around the `sample_mean` that covers approximately 95% of the numbers in the `resampled_means` array.  **You may use the following values to compute your result, but you should not perform additional resampling** - think about how you can use the CLT to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "bootstrap_7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_mean = np.mean(restaurant_sample.column(3))\n",
    "sample_sd = np.std(restaurant_sample.column(3))\n",
    "sample_size = restaurant_sample.num_rows\n",
    "\n",
    "lower_bound_normal = ...\n",
    "upper_bound_normal = ...\n",
    "print(\"95% confidence interval for the average restaurant score, computed by a normal approximation:\\n(\",lower_bound_normal, \",\", upper_bound_normal, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confidence interval should look very similar to the one you computed in Question 4. If not, try calculating the inner 95 percent using 1.96 standard deviations instead of 2 for a more precise calculation. If they are still very different, there may be an error in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing the Central Limit Theorem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem tells us that the probability distribution of the **sum** or **average** of a large random sample drawn with replacement will be roughly normal, *regardless of the distribution of the population from which the sample is drawn*.\n",
    "\n",
    "That's a pretty big claim, but the theorem doesn't stop there. It further states that the standard deviation of this normal distribution is given by \n",
    "\n",
    "$$\\frac{\\texttt{sd of the original distribution}}{\\sqrt{\\texttt{sample size}}}$$ \n",
    "\n",
    "In other words, suppose we start with *any distribution* that has standard deviation $x$, take a sample of size $n$ (where $n$ is a large number) from that distribution with replacement, and compute the **mean** of that sample. If we repeat this procedure many times, then those sample means will have a normal distribution with standard deviation $\\frac{x}{\\sqrt{n}}$.\n",
    "\n",
    "That's an even bigger claim than the first one! The proof of the theorem is beyond the scope of this class, but in this exercise, we will be exploring some data to see the CLT in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** The CLT only applies when sample sizes are \"sufficiently large.\" This isn't a very precise statement. Is 10 large?  How about 50?  The truth is that it depends both on the original population distribution and just how \"normal\" you want the result to look. Let's use a simulation to get a feel for how the distribution of the sample mean changes as sample size goes up.\n",
    "\n",
    "Consider a coin flip. If we say `Heads` is $1$ and `Tails` is $0$, then there's a 50% chance of getting a 1 and a 50% chance of getting a 0, which is definitely not a normal distribution.  The average of several coin tosses, where Heads is 1 and Tails is 0, is equal to the proportion of heads in those coin tosses, so the CLT should apply if we compute the sample proportion of heads many times.\n",
    "\n",
    "Write a function called `simulate_sample_n` that takes in a sample size $n$. It should return an array that contains 5000 sample proportions of heads, each from $n$ coin flips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_size_n(n):\n",
    "    coin_proportions = make_array(.5, .5) # our coin is fair\n",
    "    heads_proportions = make_array()\n",
    "    for i in np.arange(5000):\n",
    "        ...\n",
    "    return heads_proportions\n",
    "\n",
    "sample_size_n(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below will use the function you just defined to plot the empirical distribution of the sample mean for various sample sizes. Change the x value to several different numbers and run the code. The x- and y-scales are kept the same to facilitate comparisons. Notice the shape of the graph as the sample size increases and decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(f, x):\n",
    "    bins = np.arange(-0.01,1.05,0.02)\n",
    "    sample_props = f(x)\n",
    "    Table().with_column('Sample Size: {}'.format(x), sample_props).hist(bins=bins)\n",
    "    plt.ylim(0, 30)\n",
    "    print('Sample SD:', np.std(sample_props))\n",
    "    plt.show()\n",
    "    \n",
    "x = 4   \n",
    "graph(sample_size_n, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that even the means of samples of 10 items follow a roughly bell-shaped distribution.  A sample of 50 items looks quite bell-shaped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "clt_2"
   },
   "source": [
    "**Question 2:** In the plot for a sample size of 10, why are the bars spaced at intervals of .1, with gaps in between?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Now we will test the second claim of the CLT: That the SD of the sample mean is the SD of the original distribution, divided by the square root of the sample size.\n",
    "\n",
    "We have imported the flight delay data and computed its standard deviation for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "united = Table.read_table('united_summer2015.csv')\n",
    "united_std = np.std(united.column('Delay'))\n",
    "united_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Write a function called `empirical_sample_mean_sd` that takes a sample size `n` as its argument. The function should simulate 500 samples with replacement of size `n` from the flight delays dataset, and it should return the standard deviation of the **means of those 500 samples**.\n",
    "\n",
    "*Hint:* This function will be similar to the `sample_size_n` function you wrote earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def empirical_sample_mean_sd(n):\n",
    "    sample_means = make_array()\n",
    "    for i in np.arange(500):\n",
    "        ...\n",
    "        \n",
    "    std = ...\n",
    "    return std\n",
    "\n",
    "empirical_sample_mean_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** Now, write a function called `predict_sample_mean_sd` to find the predicted value of the standard deviation of means according to the relationship between the standard deviation of the sample mean and sample size that is discussed [here](https://umass-data-science.github.io/190fwebsite/textbook/14/5/variability-of-the-sample-mean/) in the textbook. It takes a sample size `n` (a number) as its argument.  It returns the predicted value of the standard deviation of the mean delay time for samples of size `n` from the flight delays (represented in the table `united`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using the CLT this should be 1 line of code\n",
    "def predict_sample_mean_sd(n):\n",
    "    ...\n",
    "\n",
    "predict_sample_mean_sd(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will plot the predicted and empirical SDs for the delay data for various sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "sd_table = Table().with_column('Sample Size', np.arange(1,101))\n",
    "predicted = sd_table.apply(predict_sample_mean_sd, 'Sample Size')\n",
    "empirical = sd_table.apply(empirical_sample_mean_sd, 'Sample Size')\n",
    "sd_table = sd_table.with_columns('Predicted SD', predicted, 'Empirical SD', empirical)\n",
    "sd_table.scatter('Sample Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Do our predicted and empirical values match? Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "otter": {
   "tests": {
    "q1.3": {
     "name": "q1.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(resampled_means) == 5000\n",
         "failure_message": "resampled means must be an array of resample means that is 5000 elements long",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 80.0 <= np.mean(resampled_means) <= 99.0\n",
         "failure_message": "if this test fails your resample_mean values seem to be way off",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.4": {
     "name": "q1.4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 80.0 <= lower_bound <= upper_bound <= 99.0\n",
         "failure_message": "Your values are way off. Are you calculating confidence interval correctly?",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1.7": {
     "name": "q1.7",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 80.0 <= lower_bound_normal <= upper_bound_normal <= 99.0\n",
         "failure_message": "Your values are way off. Are you calculating confidence interval correctly?",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(sample_size_n(5)) == 5000\n>>> assert np.sum(sample_size_n(5) > 1) == 0\n>>> assert np.sum(sample_size_n(5) < 0) == 0\n",
         "failure_message": "sample_size_n should return an array of 5000 proportions",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.3": {
     "name": "q2.3",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 11 <= empirical_sample_mean_sd(10) <= 15\n",
         "failure_message": "Check the logic of your function. This value is way off",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 11 <= predict_sample_mean_sd(10) <= 15\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 1: Causality and Expressions\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: otter-grader in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (4.0.0)\n",
      "Requirement already satisfied: jupytext in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (1.14.1)\n",
      "Requirement already satisfied: wrapt in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (1.14.1)\n",
      "Requirement already satisfied: pandas in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (1.1.4)\n",
      "Requirement already satisfied: dill in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (0.3.5.1)\n",
      "Requirement already satisfied: PyYAML in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (2.10.1)\n",
      "Requirement already satisfied: requests in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (2.28.0)\n",
      "Requirement already satisfied: google-api-python-client in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (2.58.0)\n",
      "Requirement already satisfied: nbformat in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (4.4.0)\n",
      "Requirement already satisfied: python-on-whales in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (0.52.0)\n",
      "Requirement already satisfied: six in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (1.12.0)\n",
      "Requirement already satisfied: fica>=0.2.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (0.2.0)\n",
      "Requirement already satisfied: click in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (8.1.3)\n",
      "Requirement already satisfied: gspread in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (5.4.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from otter-grader) (0.5.2)\n",
      "Requirement already satisfied: mdit-py-plugins in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jupytext->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=1.0.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jupytext->otter-grader) (2.1.0)\n",
      "Requirement already satisfied: toml in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jupytext->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from pandas->otter-grader) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from pandas->otter-grader) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from pandas->otter-grader) (2019.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jinja2->otter-grader) (1.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from requests->otter-grader) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from requests->otter-grader) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from requests->otter-grader) (2019.9.11)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from requests->otter-grader) (1.26.9)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-python-client->otter-grader) (2.8.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-python-client->otter-grader) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-python-client->otter-grader) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-python-client->otter-grader) (2.11.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-python-client->otter-grader) (0.20.4)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from nbformat->otter-grader) (3.0.2)\n",
      "Requirement already satisfied: ipython-genutils in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from nbformat->otter-grader) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from nbformat->otter-grader) (4.5.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from nbformat->otter-grader) (4.3.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from python-on-whales->otter-grader) (3.7.4.3)\n",
      "Requirement already satisfied: typer>=0.4.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from python-on-whales->otter-grader) (0.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from python-on-whales->otter-grader) (4.64.0)\n",
      "Requirement already satisfied: pydantic in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from python-on-whales->otter-grader) (1.9.2)\n",
      "Requirement already satisfied: sphinx in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from fica>=0.2.0->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: docutils in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from fica>=0.2.0->otter-grader) (0.19)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from click->otter-grader) (4.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-auth-oauthlib->otter-grader) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from markdown-it-py<3.0.0,>=1.0.0->jupytext->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->otter-grader) (4.21.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client->otter-grader) (1.56.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->otter-grader) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->otter-grader) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client->otter-grader) (0.2.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > \"3.0\" in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->otter-grader) (2.4.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->otter-grader) (0.14.11)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->otter-grader) (19.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->otter-grader) (50.3.0.post20201006)\n",
      "Requirement already satisfied: decorator in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from traitlets>=4.1->nbformat->otter-grader) (4.4.0)\n",
      "Requirement already satisfied: imagesize in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.2)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.1.5)\n",
      "Requirement already satisfied: babel>=1.3 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.10.3)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.3)\n",
      "Requirement already satisfied: Pygments>=2.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.4.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sphinxcontrib-jsmath in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.1)\r\n",
      "Requirement already satisfied: packaging in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (21.3)\r\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (0.7.12)\r\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (1.0.2)\r\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.0.0)\r\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from sphinx->fica>=0.2.0->otter-grader) (2.2.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->otter-grader) (3.8.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->otter-grader) (3.2.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/puritymugambi/miniconda3/envs/venv3.7/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3.0.0dev,>=1.19.0->google-api-python-client->otter-grader) (0.4.8)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install otter-grader\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading:\n",
    "This assignment uses material from textbook chapters [1](https://umass-data-science.github.io/190fwebsite/textbook/01/what-is-data-science/), [2](https://umass-data-science.github.io/190fwebsite/textbook/02/causality-and-experiments/), and [3](https://umass-data-science.github.io/190fwebsite/textbook/03/programming-in-python/). You should read this material before starting the assignment, and refer back to it as needed.\n",
    "\n",
    "## Answering Questions:\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, **please be sure to not re-assign variables throughout the notebook!** For example, if you use the name `max_temperature` in your answer to one question, do not assign that name a different value later on. \n",
    "\n",
    "## Deadline:\n",
    "\n",
    "This assignment is due Wednesday, #TODO#. Late work will not be accepted as per the [policies](https://umass-data-science.github.io/190fwebsite/policies/) page.\n",
    "\n",
    "## Collaboration:\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about what is an acceptable level of homework collaboration.\n",
    "\n",
    "## Getting Help:\n",
    "You should start early so that you have time to get help if you're stuck. Drop by at [office hours](https://umass-data-science.github.io/190fwebsite/office_hours/) for help and ask questions during the lab sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Scary Arithmetic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "adt_1"
   },
   "source": [
    "An ad for ADT Security Systems says,\n",
    "\n",
    "> \"When you go on vacation, burglars go to work [...] According to FBI statistics, over 25% of home burglaries occur between Memorial Day and Labor Day.\"\n",
    "\n",
    "**Question 1.1: 10 points** Do the data in the ad support the claim that burglars are more likely to go to work during the time between Memorial Day and Labor Day than at other times? Please explain your answer. Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2. Characters in Little Women\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The textbook describes counting the number of times that the literary characters were named in each chapter of the classic book, [Little Women](https://umass-data-science.github.io/190fwebsite/textbook/01/3/little_women.txt). In computer science, the word \"character\" also refers to a letter, digit, space, or punctuation mark; any single element of a text. The following code generates a scatter plot in which each dot corresponds to a chapter of Little Women. The horizontal position of a dot measures the number of period characters \".\" in the chapter. The vertical position measures the total number of characters. Run the cell below to produce the plot, then answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell contains code that hasn't yet been covered in the course,\n",
    "# but you should be able to interpret the scatter plot it generates.\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "little_women_url = 'https://umass-data-science.github.io/190fwebsite/textbook/01/3/little_women.txt'\n",
    "chapters = urlopen(little_women_url).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Periods',    np.char.count(chapters, '.'),\n",
    "    'Characters', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1: 10 points** About how many periods are in the chapter with the most characters? Assign either 1, 2, 3, 4, or 5 to the name `characters_q1` below.\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OK_FORMAT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ce7f8de03942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"q2.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/venv3.7/lib/python3.7/site-packages/otter/check/utils.py\u001b[0m in \u001b[0;36mevent_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv3.7/lib/python3.7/site-packages/otter/check/utils.py\u001b[0m in \u001b[0;36mevent_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEventType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshelve_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv3.7/lib/python3.7/site-packages/otter/check/notebook.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(self, question, global_env)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# run the check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Calling checker\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv3.7/lib/python3.7/site-packages/otter/execute/checker.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(cls, nb_or_test_path, test_name, global_env)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mgiven\u001b[0m \u001b[0;32mglobal\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_or_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mglobal_env\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/venv3.7/lib/python3.7/site-packages/otter/test_files/__init__.py\u001b[0m in \u001b[0;36mcreate_test_file\u001b[0;34m(path, test_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNBFORMAT_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNOTEBOOK_METADATA_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOK_FORMAT_VARNAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotebookMetadataOKTestFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OK_FORMAT'"
     ]
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 2.2: 10 points** Which of the following chapters has the most characters per period? Assign either 1, 2, or 3 to the name `characters_q2` below.\n",
    "1. The chapter with about 60 periods\n",
    "2. The chapter with about 350 periods\n",
    "3. The chapter with about 440 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To discover more interesting facts from this plot, read [Section 1.3.2](https://umass-data-science.github.io/190fwebsite/textbook/01/3/2/another-kind-of-character/) of the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Names and Assignment Statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1: 10 points** When you run the following cell, Python produces a cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best explanation of what's wrong with the code, and then assign 1, 2, 3, or 4 to `names_q1` below to indicate your answer.\n",
    "\n",
    "1. Python is smart and already knows `4 = 2 + 2`.\n",
    "\n",
    "2. `4` is a number, and it doesn't make sense to make a number be a name for something else. In Python, \"`x = 2 + 2`\" means \"assign `x` as the name for the value of `2 + 2`.\"\n",
    "\n",
    "3. It should be `2 + 2 = 4`.\n",
    "\n",
    "4. I don't get an error message. This is a trick question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2: 10 points** When you run the following cell, Python will produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = 3\n",
    "six = two plus two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, 3, or 4 to `names_q2` below to indicate your answer.\n",
    "\n",
    "1. The `plus` operation only applies to numbers, not the word \"two\".\n",
    "\n",
    "2. The name \"two\" cannot be assigned to the number 3.\n",
    "\n",
    "3. Two plus two is four, not six.\n",
    "\n",
    "4. The name `two` cannot be followed directly by another name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Job Opportunities & Education in Rural India\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [study](http://www.nber.org/papers/w16021.pdf) at UCLA investigated factors that might result in greater attention to the health and education of girls in rural India. One such factor is information about job opportunities for women. The idea is that if people know that educated women can get good jobs, they might take more care of the health and education of girls in their families, as an investment in the girls’ future potential as earners.\n",
    "\n",
    "The study focused on 160 villages outside the capital of India, all with little access to information about call centers and similar organizations that offer job opportunities to women. In 80 of the villages chosen at random, recruiters visited the village, described the opportunities, recruited women who had some English language proficiency and experience with computers, and provided ongoing support free of charge for three years. In the other 80 villages, no recruiters visited and no other intervention was made.\n",
    "\n",
    "At the end of the study period, the researchers recorded data about the school attendance and health of the children in the villages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1: 10 points** Which statement best describes the *treatment* and *control* groups for this study? Assign either 1, 2, or 3 to the name `jobs_q1` below.\n",
    "\n",
    "1. The treatment group was the 80 villages visited by recruiters, and the control group was the other 80 villages with no intervention.\n",
    "\n",
    "2. The treatment group was the 160 villages selected, and the control group was the rest of the villages outside the capital of India.\n",
    "\n",
    "3. There is no clear notion of *treatment* and *control* group in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs_q1 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2: : 10 points** Was this an observational study or a randomized controlled experiment? Assign either 1, 2, or 3 to the name `jobs_q2` below.\n",
    "\n",
    "1. This was an observational study.\n",
    "\n",
    "2. This was a randomized controlled experiment.  \n",
    "\n",
    "3. This was a randomized observational study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs_q2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The treatment was performed on girls. The boys were mentioned as contrasts to argue the causal effect of the treatment on girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Differences between Universities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1: 5 points** Suppose you'd like to *quantify* how *dissimilar* two universities are, using three quantitative characteristics.  The US Department of Education data on [UMass](https://collegescorecard.ed.gov/school/?166629-University-of-Massachusetts-Amherst) and [UConn](https://collegescorecard.ed.gov/school/?129020-University-of-Connecticut) describes the following three variables (among many others):\n",
    "\n",
    "| Trait                                | UMass  | Uconn  |\n",
    "|--------------------------------------|--------|--------|\n",
    "| Average annual cost to attend ($)    | 18,869 | 20,023 |\n",
    "| Graduation rate (percentage)         | 77     | 82     |\n",
    "| Socioeconomic Diversity (percentage) | 24     | 21     |\n",
    "\n",
    "You decide to define the dissimilarity between two universities as the **maximum of the absolute values of the 3 differences in these values of these variables**.\n",
    "\n",
    "Using this method, compute the dissimilarity between UMass and UConn.  Name the result `dissimilarity`.  Use a single expression (a single line of code) to compute the answer.  Let Python perform all the arithmetic (like subtracting 82 from 77) rather than simplifying the expression yourself. The built-in `abs` function takes absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dissimilarity = ...\n",
    "dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Nearsightedness Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Myopia, or nearsightedness, results from a number of genetic and environmental factors. In 1999, Quinn et al studied the relation between myopia and ambient lighting at night (for example, from nightlights or room lights) during childhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "nearsightedness_1"
   },
   "source": [
    "**Question 6.1: 5 points** The data were gathered by the following procedure, reported in the study. “Between January and June 1998, parents of children aged 2-16 years [...] that were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire on the child’s light exposure both at present and before the age of 2 years.” Was this study observational, or was it a controlled experiment? Open and edit the cell below to provide your explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "nearsightedness_2"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.2: 5 points** The study found that of the children who slept with a room light on before the age of 2, 55% were myopic. Of the children who slept with a night light on before the age of 2, 34% were myopic. Of the children who slept in the dark before the age of 2, 10% were myopic. The study concluded that, \"The prevalence of myopia [...] during childhood was strongly associated with ambient light exposure during sleep at night in the first two years after birth.\"\n",
    "\n",
    "Do the data support this statement? You may interpret “strongly” in any reasonable qualitative way. Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "nearsightedness_3"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.3: 5 points** On May 13, 1999, CNN reported the results of this study under the headline, “Night light may lead to nearsightedness.” Does the conclusion of the study claim that night light causes nearsightedness? Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_problem_id": "nearsightedness_4"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.4: 5 points** The final paragraph of the CNN report said that “several eye specialists” had pointed out that the study should have accounted for heredity.\n",
    "\n",
    "Myopia is passed down from parents to children. It's reasonable to suppose that myopic parents are more likely to leave lights on in their children's rooms than other parents. In what way could this have affected the data? Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 7. Studying the Survivors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.1: 5 points**The Reverend Henry Whitehead was skeptical of John Snow’s conclusion about the Broad Street pump. After the Broad Street cholera epidemic ended, Whitehead set about trying to prove Snow wrong.  (The history of the event is detailed [here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "He realized that Snow had focused his analysis almost entirely on those who had died. Whitehead, therefore, investigated the drinking habits of people in the Broad Street area who had not died in the outbreak.\n",
    "\n",
    "What is the main reason it was important to study this group?\n",
    "\n",
    "1) If Whitehead had found that many people had drunk water from the Broad Street pump and not caught cholera, that would have been evidence against Snow's hypothesis.\n",
    "\n",
    "2) Survivors could provide additional information about what else could have caused the cholera, potentially unearthing another cause.\n",
    "\n",
    "3) Through considering the survivors, Whitehead could have identified a cure for cholera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign survivor_answer to 1, 2, or 3\n",
    "survivor_answer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Whitehead ended up finding further proof that the Broad Street pump played the central role in spreading the disease to the people who lived near it. Eventually, he became one of Snow’s greatest defenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've finished homework 1!  Be sure to run the notebook tests and verify that they all pass, **your homework will need to pass more tests in gradescope**. Choose **Save and Checkpoint** from the **File** menu, then upload the .ipynb to gradescope to submit your work.  You may submit to gradescope as many times as you want until the deadline. Make sure to pay attention to what tests you are passing and failing after submiting!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "otter": {
   "tests": {
    "q2.1": {
     "name": "q2.1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(characters_q1, int)\n",
         "failure_message": "If this test failed your answer is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(characters_q2, int)\n",
         "failure_message": "If this test failed your answer is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(names_q1, int)\n>>> assert isinstance(names_q2, int)\n",
         "failure_message": "If this test failed your answers are not integers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(jobs_q1, int)\n>>> assert isinstance(jobs_q2, int)\n",
         "failure_message": "If this test failed your answers are not integers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(dissimilarity, (int, float))\n",
         "failure_message": "If this test failed your answers is not a number",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(survivor_answer, int)\n",
         "failure_message": "If this test failed your answers is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
